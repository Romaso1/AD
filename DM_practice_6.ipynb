{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i8adKFQS7E-"
      },
      "source": [
        "# **Лабораторна робота 6: Пошук аномалій та вирішення задачі *anomaly detection* за допомогою бібліотек `scikit-learn`та `PyTorch`**\n",
        "**Всі завдання виконуються індивідуально. Використання запозиченого коду буде оцінюватись в 0 балів.**\n",
        "\n",
        "**Лабораторні роботи де в коді буде використаня КИРИЛИЦІ будуть оцінюватись в 20 балів.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvneQUbQRRqZ"
      },
      "source": [
        "### Мета роботи:\n",
        "Ознайомитися з основними методами виявлення аномалій, навчитися використовувати бібліотеки `scikit-learn` та `PyTorch` для реалізації алгоритмів пошуку аномалій, проаналізувати ефективність різних методів на реальних наборах даних з Kaggle.\n",
        "\n",
        "\n",
        "### Опис завдання:\n",
        "\n",
        "1. **Постановка задачі**:\n",
        "   Використовуючи один із доступних наборів даних Kaggle (наприклад, *Credit Card Fraud Detection*, *Network Intrusion*, або інші), вам потрібно розв'язати задачу виявлення аномалій. Основна мета — ідентифікувати аномальні записи серед нормальних. Вибраний набір даних повинен містити мітки аномалій для перевірки результатів.\n",
        "\n",
        "2. **Етапи виконання завдання**:\n",
        "   - Завантажте та підготуйте набір даних.\n",
        "   - Проведіть попередню обробку даних (масштабування, заповнення пропущених значень, видалення нерелевантних ознак).\n",
        "   - Використайте різні методи виявлення аномалій:\n",
        "     - **Методи з бібліотеки scikit-learn**:\n",
        "       - Isolation Forest\n",
        "       - One-Class SVM\n",
        "       - Local Outlier Factor (LOF)\n",
        "     - **Методи з використанням PyTorch**:\n",
        "       - Автоенкодери для виявлення аномалій.\n",
        "   - Порівняйте отримані результати, обчисліть метрики якості (Precision, Recall, F1-Score).\n",
        "   - Оцініть, який метод найкраще підходить для вирішення задачі на вашому наборі даних.\n",
        "\n",
        "### Покрокова інструкція\n",
        "\n",
        "1. **Підготовка середовища**:\n",
        "   - Встановіть необхідні бібліотеки:\n",
        "     ```\n",
        "     pip install scikit-learn torch pandas numpy matplotlib\n",
        "     ```\n",
        "\n",
        "2. **Вибір набору даних з Kaggle**:\n",
        "   Зареєструйтесь на Kaggle та оберіть один із наборів даних для виявлення аномалій. Наприклад:\n",
        "   - [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)\n",
        "   - [Network Intrusion Detection](https://www.kaggle.com/xyuanh/benchmarking-datasets)\n",
        "\n",
        "3. **Попередня обробка даних**:\n",
        "   - Завантажте дані та проведіть їхню початкову обробку.\n",
        "   - Масштабуйте ознаки за допомогою `StandardScaler` або `MinMaxScaler`.\n",
        "   - Розділіть дані на навчальну і тестову вибірки.\n",
        "\n",
        "4. **Методи з бібліотеки `scikit-learn`**:\n",
        "\n",
        "   - **Isolation Forest**:\n",
        "     ```\n",
        "     from sklearn.ensemble import IsolationForest\n",
        "     ```\n",
        "\n",
        "   - **One-Class SVM**:\n",
        "     ```\n",
        "     from sklearn.svm import OneClassSVM\n",
        "     ```\n",
        "\n",
        "   - **Local Outlier Factor**:\n",
        "     ```\n",
        "     from sklearn.neighbors import LocalOutlierFactor\n",
        "     ```\n",
        "\n",
        "5. **Методи на основі нейронних мереж (PyTorch)**:\n",
        "\n",
        "   Використайте автоенкодер для пошуку аномалій. Побудуйте нейронну мережу з енкодером і декодером. Під час навчання порівняйте відновлені дані з вхідними та обчисліть помилку. Записи з великою помилкою можуть бути аномаліями.\n",
        "\n",
        "   - **Реалізація автоенкодера**:\n",
        "     ```\n",
        "     import torch\n",
        "     import torch.nn as nn\n",
        "     import torch.optim as optim\n",
        "     ```\n",
        "\n",
        "6. **Оцінка результатів**:\n",
        "   Використовуйте метрики оцінки якості:\n",
        "   - `Precision`, `Recall`, `F1-score`\n",
        "   ```\n",
        "   from sklearn.metrics import classification_report\n",
        "   ```\n",
        "\n",
        "7. **Звіт**:\n",
        "   - Поясніть, який метод дав найкращі результати.\n",
        "   - Проаналізуйте, чому деякі методи працюють краще на вашому наборі даних.\n",
        "   - Оцініть можливості використання глибоких нейронних мереж (автоенкодерів) для вирішення задачі.\n",
        "\n",
        "\n",
        "### Результати, які необхідно надати:\n",
        "1. Код рішення у вигляді Jupyter Notebook з аналізом результатів та поясненнями.\n",
        "\n",
        "\n",
        "### Дедлайн:\n",
        "[23 жовтня 23:59]\n",
        "\n",
        "\n",
        "### Корисні ресурси:\n",
        "- [Документація PyTorch](https://pytorch.org/docs/stable/index.html)\n",
        "- [Документація scikit-learn](https://scikit-learn.org/stable/documentation.html)\n",
        "- [Kaggle Datasets](https://www.kaggle.com/datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NeqgMqm2UETO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Розмір навчальної вибірки: (22784, 30)\n",
            "Розмір тестової вибірки: (5697, 30)\n",
            "Isolation Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00      5691\n",
            "           1       0.07      0.67      0.13         6\n",
            "\n",
            "    accuracy                           0.99      5697\n",
            "   macro avg       0.54      0.83      0.56      5697\n",
            "weighted avg       1.00      0.99      0.99      5697\n",
            "\n",
            "One-Class SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.94      5691\n",
            "           1       0.01      1.00      0.02         6\n",
            "\n",
            "    accuracy                           0.88      5697\n",
            "   macro avg       0.50      0.94      0.48      5697\n",
            "weighted avg       1.00      0.88      0.93      5697\n",
            "\n",
            "Local Outlier Factor\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00      5691\n",
            "           1       0.07      0.67      0.13         6\n",
            "\n",
            "    accuracy                           0.99      5697\n",
            "   macro avg       0.53      0.83      0.56      5697\n",
            "weighted avg       1.00      0.99      0.99      5697\n",
            "\n",
            "Epoch [5/10], Loss: 0.4996\n",
            "Epoch [10/10], Loss: 0.4886\n",
            "Autoencoder\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00      5691\n",
            "           1       0.07      0.67      0.13         6\n",
            "\n",
            "    accuracy                           0.99      5697\n",
            "   macro avg       0.53      0.83      0.56      5697\n",
            "weighted avg       1.00      0.99      0.99      5697\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('creditcard.csv')\n",
        "\n",
        "# вибирає меньшу вибірку данних для швидшого навчання\n",
        "data_sample = data.sample(frac=0.1, random_state=42)  #10% даних\n",
        "\n",
        "# маштаб ознак\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data_sample.drop('Class', axis=1))\n",
        "\n",
        "# роздідення на тест і навч вибірки\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_scaled, data_sample['Class'], test_size=0.2, random_state=42)\n",
        "\n",
        "# перевірка розміру данних\n",
        "print(f'Розмір навчальної вибірки: {X_train.shape}')\n",
        "print(f'Розмір тестової вибірки: {X_test.shape}')\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------#\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Isolation Forest\n",
        "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
        "iso_forest.fit(X_train)\n",
        "y_pred_train_iso = iso_forest.predict(X_train)\n",
        "y_pred_test_iso = iso_forest.predict(X_test)\n",
        "\n",
        "# перетворення результ\n",
        "y_pred_test_iso = np.where(y_pred_test_iso == 1, 0, 1)\n",
        "print(\"Isolation Forest\")\n",
        "print(classification_report(y_test, y_pred_test_iso))\n",
        "\n",
        "# One-Class SVM\n",
        "svm = OneClassSVM(nu=0.01, kernel=\"rbf\", gamma=0.1)\n",
        "svm.fit(X_train)\n",
        "y_pred_train_svm = svm.predict(X_train)\n",
        "y_pred_test_svm = svm.predict(X_test)\n",
        "\n",
        "# перетворення результ\n",
        "y_pred_test_svm = np.where(y_pred_test_svm == 1, 0, 1)\n",
        "print(\"One-Class SVM\")\n",
        "print(classification_report(y_test, y_pred_test_svm))\n",
        "\n",
        "# Local Outlier Factor\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.01)\n",
        "y_pred_train_lof = lof.fit_predict(X_train)\n",
        "y_pred_test_lof = lof.fit_predict(X_test)\n",
        "\n",
        "# перетворення результ\n",
        "y_pred_test_lof = np.where(y_pred_test_lof == 1, 0, 1)\n",
        "print(\"Local Outlier Factor\")\n",
        "print(classification_report(y_test, y_pred_test_lof))\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------#\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# автоенкодер\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded\n",
        "\n",
        "# пайторч підготовка\n",
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32))\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# ініц моделі\n",
        "model = Autoencoder(input_dim=X_train.shape[1])\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "#автоенкодер навч\n",
        "num_epochs = 10  # зменьшив кількість епох\n",
        "for epoch in range(num_epochs):\n",
        "    for data in train_loader:\n",
        "        inputs = data[0]\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------#\n",
        "\n",
        "# обч помилки відновлення для тест данних\n",
        "with torch.no_grad():\n",
        "    reconstructions = model(torch.tensor(X_test, dtype=torch.float32))\n",
        "    loss = torch.mean((reconstructions - torch.tensor(X_test, dtype=torch.float32))**2, dim=1)\n",
        "    y_pred_test_ae = (loss > torch.quantile(loss, 0.99)).numpy().astype(int)\n",
        "    \n",
        "print(\"Autoencoder\")\n",
        "print(classification_report(y_test, y_pred_test_ae))\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------------------#\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "На основі отриманих результатів, найкращим методом для виявлення аномалій у даному наборі даних є Isolation Forest. Він показав збалансовані результати між precision та recall для класу 1."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
